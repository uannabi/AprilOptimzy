{"id":137614,"url":"http://en.wikipedia.org/wiki/Genetic_algorithm","text":"A genetic algorithm is an algorithm that imitates the process of natural selection. They help solve optimization and search problems. Genetic algorithms are part of the bigger class of evolutionary algorithms. Genetic algorithms imitate natural biological processes, such as inheritance, mutation, selection and crossover.\nThe concept of genetic algorithms is a search technique often used in computer science to find complex, non-obvious solutions to algorithmic optimisation and search problems. Genetic algorithms are global search heuristics.\nWhat is it.\nNatural evolution can be modeled as a game, in which the rewards for an organism that plays a good game of life are the passing on of its genetic material to its successors and its continued survival. In natural evolution, how well an individual performs depends on its who it works with and who it competes with, as well as the environment. Genetic algorithms are a simulation of natural selection on a population of candidate solutions to an optimization problem (chromosomes, individuals, creatures, or phenotypes).\nCandidates are evaluated and crossbred in an attempt to make good solutions. Such solutions may take a lot of time and are not obvious to a human. An evolutionary phase is started with a population of randomly generated beings. In each generation, the fitness of every individual in the population is evaluated. Some are randomly selected from the current population (based on their fitness) and modified (recombined and possibly randomly mutated) to form a new population. The cycle repeats with this new population. The algorithm ends either after a set number of generations have passed, or a good fitness level has been reached for the population. If the algorithm has ended due to reaching a maximum number of generations, it does not necessarily mean a good fitness level has been obtained.\nExample.\nThe above description is abstract. A concrete example helps.\nIn general.\nGenetic algorithms are good at solving problems that include timetabling and scheduling. They have also been applied to engineering. They are often used to solve global optimization problems.\nAs a general rule of thumb, genetic algorithms might be useful in problem domains that have a complex fitness landscape as mixing is designed to move the population away from local optima that a traditional hill climbing algorithm might get stuck in. Commonly used crossover operators cannot change any uniform population. Mutation alone can provide ergodicity of the overall genetic algorithm process (seen as a Markov chain).\nExamples of problems solved by genetic algorithms include: mirrors designed to funnel sunlight to a solar collector, antennae designed to pick up radio signals in space, walking methods for computer figures, optimal design of aerodynamic bodies in complex flowfields\nIn his \"Algorithm Design Manual\", Skiena advises against genetic algorithms for any task: \"It is quite unnatural to model applications in terms of genetic operators like mutation and crossover on bit strings. The pseudobiology adds another level of complexity between you and your problem. Second, genetic algorithms take a very long time on nontrivial problems. [...] The analogy with evolution\u2014where significant progress require [sic] millions of years\u2014can be quite appropriate.\n[...] I have never encountered any problem where genetic algorithms seemed to me the right way to attack it. Further, I have never seen any computational results reported using genetic algorithms that have favorably impressed me. Stick to simulated annealing for your heuristic search voodoo needs.\"\nBoard games.\nBoard games are a very relevant part of the area of genetic algorithms as applied to game theory problems. Much of the early work on computational intelligence and games was directed toward classic board games, such as tic-tac-toe, chess, and checkers. Board games can now, in most cases, be played by a computer at a higher level than the best humans, even with blind exhaustive search techniques. Go is a noted exception to this tendency, and has so far resisted machine attack. The best Go computer players now play at the level of a good novice. Go strategy is said to rely heavily on pattern recognition, and not just logical analysis as with chess and other more piece-independent games. The huge effective branching factor required for finding high quality solutions heavily restricts the look-ahead that can be used within a move sequence search.\nComputer games.\nThe genetic algorithm can be used in computer games to create artificial intelligence (the computer plays against you). This allows for a more realistic game experience; if a human player can find a sequence of steps which always lead to success even when repeated in different games, there can be no challenge left. Conversely if a learning technique such as a genetic algorithm for a strategist can avoid repeating past mistakes, the game will have more playability.\nThe fitness function accepts a mutated instantiation of an entity and measures its quality. This function is customized to the problem domain. In many cases, particularly those involving code optimization, the fitness function may simply be a system timing function. Once a genetic representation and fitness function are defined, a genetic algorithm will instantiate initial candidates as described before, and then improve through repetitive application of mutation, crossover, inversion and selection operators (as defined according to the problem domain).\nHistory.\nIn 1950, Alan Turing proposed a \"learning machine\" which would parallel the principles of evolution. Computer simulation of evolution started as early as in 1954 with the work of Nils Aall Barricelli, who was using the computer at the Institute for Advanced Study in Princeton, New Jersey. His 1954 publication was not widely noticed. Starting in 1957, the Australian quantitative geneticist Alex Fraser published a series of papers on simulation of artificial selection of organisms with multiple loci controlling a measurable trait. From these beginnings, computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970) and Crosby (1973). Fraser's simulations included all of the essential elements of modern genetic algorithms. In addition, Hans-Joachim Bremermann published a series of papers in the 1960s that also adopted a population of solution to optimization problems, undergoing recombination, mutation, and selection. Bremermann's research also included the elements of modern genetic algorithms. Other noteworthy early pioneers include Richard Friedberg, George Friedman, and Michael Conrad. Many early papers are reprinted by Fogel (1998).\nAlthough Barricelli, in work he reported in 1963, had simulated the evolution of ability to play a simple game, artificial evolution became a widely recognized optimization method as a result of the work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early 1970s \u2013 Rechenberg's group was able to solve complex engineering problems through evolution strategies. Another approach was the evolutionary programming technique of Lawrence J. Fogel, which was proposed for generating artificial intelligence. Evolutionary programming originally used finite state machines for predicting environments, and used variation and selection to optimize the predictive logics. Genetic algorithms in particular became popular through the work of John Holland in the early 1970s, and particularly his book \"Adaptation in Natural and Artificial Systems\" (1975). His work originated with studies of cellular automata, conducted by Holland and his students at the University of Michigan. Holland introduced a formalized framework for predicting the quality of the next generation, known as Holland's schema theorem. Research in GAs remained largely theoretical until the mid-1980s, when The First International Conference on Genetic Algorithms was held in Pittsburgh, Pennsylvania.","categories":[],"infobox_types":[],"annotations":[{"uri":"Algorithm","surface_form":"algorithm","offset":26},{"uri":"Imitation","surface_form":"imitates","offset":41},{"uri":"Natural_selection","surface_form":"natural selection","offset":65},{"uri":"Optimization_(computer_science)","surface_form":"optimization","offset":100},{"uri":"Evolutionary_algorithm","surface_form":"evolutionary algorithm","offset":185},{"uri":"Heredity","surface_form":"inheritance","offset":275},{"uri":"Mutation","surface_form":"mutation","offset":288},{"uri":"Crossing_over","surface_form":"crossover","offset":312},{"uri":"Computer_science","surface_form":"computer science","offset":393},{"uri":"Game_theory","surface_form":"game","offset":597},{"uri":"Organism","surface_form":"organism","offset":631},{"uri":"DNA","surface_form":"genetic material","offset":697},{"uri":"Simulation","surface_form":"simulation","offset":926},{"uri":"Chromosome","surface_form":"chromosomes","offset":1025},{"uri":"Stochastic_process","surface_form":"randomly","offset":1399},{"uri":"Timeline","surface_form":"timetabling","offset":2018},{"uri":"Engineering","surface_form":"engineering","offset":2077},{"uri":"Combinatorial_optimization","surface_form":"optimization","offset":2126},{"uri":"Markov_chain","surface_form":"Markov chain","offset":2562},{"uri":"Simulated_annealing","surface_form":"simulated annealing","offset":3564},{"uri":"Game_theory","surface_form":"game theory","offset":3723},{"uri":"Go","surface_form":"Go","offset":4037},{"uri":"Branching_factor","surface_form":"branching factor","offset":4351},{"uri":"Artificial_intelligence","surface_form":"artificial intelligence","offset":4571},{"uri":"Alan_Turing","surface_form":"Alan Turing","offset":5556},{"uri":"Nils_Aall_Barricelli","surface_form":"Nils Aall Barricelli","offset":5726},{"uri":"Institute_for_Advanced_Study","surface_form":"Institute for Advanced Study","offset":5782},{"uri":"Princeton%2C_New_Jersey","surface_form":"Princeton, New Jersey","offset":5814},{"uri":"Alex_Fraser_(scientist)","surface_form":"Alex Fraser","offset":5939},{"uri":"Artificial_selection","surface_form":"artificial selection","offset":5997},{"uri":"Loci","surface_form":"loci","offset":6045},{"uri":"Trait","surface_form":"trait","offset":6075},{"uri":"Hans-Joachim_Bremermann","surface_form":"Hans-Joachim Bremermann","offset":6382},{"uri":"David_B._Fogel","surface_form":"Fogel","offset":6778},{"uri":"Artificial_evolution","surface_form":"artificial evolution","offset":6904},{"uri":"Ingo_Rechenberg","surface_form":"Ingo Rechenberg","offset":6999},{"uri":"Hans-Paul_Schwefel","surface_form":"Hans-Paul Schwefel","offset":7019},{"uri":"Evolution_strategy","surface_form":"evolution strategies","offset":7143},{"uri":"Lawrence_J._Fogel","surface_form":"Lawrence J. Fogel","offset":7228},{"uri":"Evolutionary_programming","surface_form":"Evolutionary programming","offset":7306},{"uri":"Finite-state_machine","surface_form":"finite state machines","offset":7347},{"uri":"Variation","surface_form":"variation","offset":7407},{"uri":"John_Henry_Holland","surface_form":"John Holland","offset":7534},{"uri":"Cellular_automata","surface_form":"cellular automata","offset":7684},{"uri":"John_Henry_Holland","surface_form":"Holland","offset":7716},{"uri":"University_of_Michigan","surface_form":"University of Michigan","offset":7748},{"uri":"Holland%27s_schema_theorem","surface_form":"Holland's schema theorem","offset":7874},{"uri":"Pittsburgh%2C_Pennsylvania","surface_form":"Pittsburgh, Pennsylvania","offset":8040}]}