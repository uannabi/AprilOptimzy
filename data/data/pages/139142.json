{"id":139142,"url":"http://en.wikipedia.org/wiki/Data_parallelism","text":"e=\"preserve\">Data parallelism (also known as loop-level parallelism) is a form of parallel computing for multiple processors using a technique for distributing the data across different parallel processor nodes. It contrasts to task parallelism as another form of parallelism.\nIn a multiprocessor system where each one is executing a single set of instructions, data parallelism is achieved when each processor performs the same task on different pieces of distributed data. In some situations, a single execution thread controls operations on all pieces of data. In others, different threads control the operation, but they execute the same code.\nFor example, if we are running code on a 2-processor system (CPUs A and B) in a parallel computing environment, and we want to do a task on some data D, it is possible to tell CPU A to do that task on one part of D and CPU B on another part of D simultaneously (at the same time), in order to reduce the runtime of the execution.\nData parallelism is used by many applications especially data processing applications; one of the examples is database applications. Most real programs use a combination of data parallelism and task parallelism.","categories":[],"infobox_types":[],"annotations":[{"uri":"Parallel_computing","surface_form":"parallel computing","offset":82},{"uri":"Central_processing_unit","surface_form":"processor","offset":114},{"uri":"Technique","surface_form":"technique","offset":133},{"uri":"Task_parallelism","surface_form":"task parallelism","offset":228},{"uri":"Multiprocessing","surface_form":"multiprocessor","offset":282},{"uri":"CPU","surface_form":"CPU","offset":709},{"uri":"Parallel_computing","surface_form":"parallel computing","offset":728},{"uri":"Runtime","surface_form":"runtime","offset":952},{"uri":"Database","surface_form":"database","offset":1088},{"uri":"Task_parallelism","surface_form":"task parallelism","offset":1172}]}