{"id":140621,"url":"http://en.wikipedia.org/wiki/Very_long_instruction_word","text":"Very Long Instruction Word or VLIW which refers to a CPU architecture designed to take advantage of instruction level parallelism (ILP) but at minimum level of hardware complexities. (Alternatively, Variable Length Instruction Word or VLIW a refers to a CPU instruction (instruction set) designed to load (or copy) a literal value count of inline Machine code to the on-chip RAM for higher speed CPU decoding.)\nA processor that executes every instruction one after the other (i.e. a non-pipelined scalar architecture) may use processor resources inefficiently, leading to poor performance.\nAll above ILP techniques are implemented at a higher cost with increased hardware complexity. Before executing any operations in-parallel, the processor must verify that the instructions do not have interdependencies. There are many types of interdependencies, but a simple example would be a program in which the first instruction's result is used as an input for the second instruction. They clearly cannot execute at the same time, and the second instruction cannot be executed before the first. Modern out-of-order processors use major resources in order to take advantage of these techniques, since the scheduling of instructions must be determined dynamically as a program executes based on dependencies.\nThe VLIW approach, on the other hand, executes operation in parallel based on a fixed schedule determined when programs are compiled. Since determining the order of execution of operations (including which operations can execute simultaneously) is handled by the compiler, the processor does not need the complex hardware required by ILP techniques described above. As a result, VLIW CPUs offer significant computational power with less hardware complexity but with greater compiler design complexity.","categories":[],"infobox_types":[],"annotations":[{"uri":"Central_processing_unit","surface_form":"CPU","offset":53},{"uri":"Computer_architecture","surface_form":"architecture","offset":57},{"uri":"Instruction_level_parallelism","surface_form":"instruction level parallelism","offset":100},{"uri":"Central_processing_unit","surface_form":"CPU","offset":254},{"uri":"Instruction_set","surface_form":"instruction set","offset":271},{"uri":"Machine_code","surface_form":"Machine code","offset":347},{"uri":"Central_processing_unit","surface_form":"CPU","offset":396},{"uri":"Instruction_(computer_science)","surface_form":"instruction","offset":443},{"uri":"Instruction_pipelining","surface_form":"pipelined","offset":487},{"uri":"Efficiency","surface_form":"inefficiently","offset":546},{"uri":"Computer_performance","surface_form":"performance","offset":577},{"uri":"Instruction_level_parallelism","surface_form":"ILP","offset":600},{"uri":"Technique","surface_form":"technique","offset":604},{"uri":"Dependence_analysis","surface_form":"interdependencies","offset":789},{"uri":"Out-of-order_execution","surface_form":"out-of-order","offset":1096},{"uri":"Processor","surface_form":"processor","offset":1109},{"uri":"Compiler","surface_form":"compiled","offset":1425},{"uri":"Instruction_(computer_science)","surface_form":"operations","offset":1479},{"uri":"Instruction_level_parallelism","surface_form":"ILP","offset":1635},{"uri":"Technique","surface_form":"technique","offset":1639},{"uri":"Computation","surface_form":"computation","offset":1708},{"uri":"Compiler","surface_form":"compiler","offset":1775}]}