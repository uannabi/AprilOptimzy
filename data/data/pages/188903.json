{"id":188903,"url":"http://en.wikipedia.org/wiki/Big_O_notation","text":"e=\"preserve\">In mathematics and computer science, Big O notation is a way of comparing rates of growth of different functions. It is often used to compare the efficiency of different algorithms, which is done by calculating how much memory is needed, and how much time it takes to complete.\nThe Big O notation is often used in identifying how complex a problem is, also known as the problem's complexity class. The mathematician Paul Bachmann (1837-1920) was the first to use this notation, in the second edition of his book \"Analytische Zahlentheorie\", in 1896. Edmund Landau (1877-1938) made the notation popular. For this reason, when people talk about a Landau symbols, they refer to this notation.\nBig O notation is named after the term \"order of the function\", which refers to the growth of functions. Big O notation is used to find the upper bound (the highest possible amount) of the function's growth rate, meaning it works out the longest time it will take to turn the input into the output. This means an algorithm can be grouped by how long it can take in a worst-case scenario, where the longest route will be taken every time.\nMore specifically, given two positive functions formula_1 and formula_1, we say that formula_1 is in the big O of formula_1 (written formula_1) if for large enough formula_1, formula_1 for some constant formula_1.\nBig O is an expression that finds worst-case scenario run-time, showing how efficient an algorithm is without having to run the program on a computer. This is also useful due to the fact that different computers may have different hardware, and therefore need different amounts of time to complete it. Since Big O always assumes the worst-case, it can show a consistent measurement of speed: regardless of the hardware, formula_1 is always going to complete faster than formula_1, because they have different levels of efficiency.\nExamples.\nThe following examples all use code written in Python. Note that this is not a complete list of Big O types.\nConstant.\nreturn x * 2 #Return the value of x times 2\nAfter accepting the input, this function will always take one step to return an output. It is constant because it will always take the same amount of time, so it is formula_1.\nLinear.\ni = 1 #Create a counter called \"i\" with a value of 1\nwhile i <= n: #While i is less-than or equal to n\nprint(i) #Print the value of i\ni = i + 1 #Redefine i as \"the value of i + 1\"\nIf we were to input the value of 5, then this would output formula_1, requiring 5 loops to complete. Similarly, if we input 100, then it would output formula_1, requiring 100 loops to complete. If the input is formula_1, then the algorithm's run time is exactly formula_1 loops every time, therefore it is formula_1.\nFactorial.\nimport itertools #Import the itertools library\ncities = ['London', 'Paris', 'Berlin', 'Amsterdam', 'Rome'] #An array of our chosen cities\nfor i in itertools.permutations(cities): #For each permutation of our items (assigned to variable \"i\")\nHere, our input list is 5 items long, and for every selection our remaining options decreases by 1. In other words, our 5 inputs choose formula_1 items (or formula_1). If our input is formula_1 cities long, then the number of outputs is formula_1; in general, assuming that we go through every permutation, then we will require formula_1 loops to complete it.\nLittle-o notation.\nA related concept to big-O notation is little-o notation. Big-O is used to say that a function goes not grow faster than another function, while little-o is used to say that a function grows more slowly than another function. If two functions grow at the same rate, big-O can be used but little-o cannot. The difference between big-O and little-o is similar to the difference between formula_1 and <math>\uFFFD\uFFFD/math>.","categories":[],"infobox_types":[],"annotations":[{"uri":"Mathematics","surface_form":"mathematics","offset":16},{"uri":"Computer_science","surface_form":"computer science","offset":32},{"uri":"Function_(mathematics)","surface_form":"functions","offset":116},{"uri":"Algorithm","surface_form":"algorithm","offset":183},{"uri":"Computer_memory","surface_form":"memory","offset":233},{"uri":"Complexity_class","surface_form":"complexity class","offset":393},{"uri":"Paul_Bachmann","surface_form":"Paul Bachmann","offset":429},{"uri":"Edmund_Landau","surface_form":"Edmund Landau","offset":563},{"uri":"Function","surface_form":"function","offset":797},{"uri":"Computer_hardware","surface_form":"hardware","offset":1586},{"uri":"Python_(programming_language)","surface_form":"Python","offset":1943}]}