{"id":307919,"url":"http://en.wikipedia.org/wiki/Central_limit_theorem","text":"In probability theory and statistics, the central limit theorems, abbreviated as CLT, are theorems about the limiting behaviors of aggregated probability distributions. They say that given a large number of independent random variables, their sum will follow a stable distribution. If the variance of the random variables is finite, then a Gaussian distribution will result. This is one of the reasons why this distribution is also known as \"normal\" distribution.\nThe best known and most important of these is known as \"the central limit theorem\". It is about large numbers of random variables with the same distribution, each with an identical finite variance and expected value.\nMore specifically, if formula_1 are \"n\" identical and independently distributed random variables with mean formula_1 and standard deviation formula_1, then the distribution of their sample mean, formula_1, as \"n\" gets large, is approximately normal with mean formula_1 and standard deviation formula_1. Furthermore, the distribution of their sum, formula_1, as \"n\" gets large, is also approximately normal, with mean formula_1 and standard deviation formula_1.\nThere are different generalisations of this theorem. Some of these generalisations no longer require an identical distribution of all random variables. In these generalisations, another precondition makes sure that no single random variable has a bigger influence on the outcome than the others. Examples are the Lindeberg and Lyapunov conditions.\nThe name of the theorem is based on a paper George P\u00F3lya written in 1920, \"About the Central Limit Theorem in Probability Theory and the Moment problem\".","categories":[],"infobox_types":[],"annotations":[{"uri":"Probability_theory","surface_form":"probability theory","offset":3},{"uri":"Statistics","surface_form":"statistics","offset":26},{"uri":"Theorem","surface_form":"theorem","offset":90},{"uri":"Probability_distribution","surface_form":"probability distributions","offset":142},{"uri":"Random_variable","surface_form":"random variable","offset":219},{"uri":"Stable_distribution","surface_form":"stable distribution","offset":261},{"uri":"Variance","surface_form":"variance","offset":289},{"uri":"Finite","surface_form":"finite","offset":325},{"uri":"Gaussian_distribution","surface_form":"Gaussian distribution","offset":340},{"uri":"Expected_value","surface_form":"expected value","offset":665},{"uri":"Mean","surface_form":"mean","offset":783},{"uri":"Standard_deviation","surface_form":"standard deviation","offset":802},{"uri":"Lindeberg%27s_condition","surface_form":"Lindeberg","offset":1455},{"uri":"Lyapunov_condition","surface_form":"Lyapunov condition","offset":1469},{"uri":"George_P%C3%B3lya","surface_form":"George P\u00F3lya","offset":1534},{"uri":"Moment_(mathematics)","surface_form":"Moment","offset":1627}]}