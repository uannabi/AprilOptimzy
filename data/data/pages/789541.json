{"id":789541,"url":"http://en.wikipedia.org/wiki/Optimal_control","text":"e=\"preserve\">Optimal control theory is a theory from mathematics. It looks at how to find a good (usually optimal) solution in a dynamic system. The system is described by a function, and the problem often is to find values that minimize or maximize this function over an interval.\nIn addition, there may be state restrictions. The state the system is in at a given point in time has to meet certain conditions.\nMost of the foundations of optimal control theory were done by Lev Pontryagin, in the Soviet Union, and Richard Bellman in the United States.\nAn example of an optimal control problem might be a driver who wants to get from A to B in as little time as possible. There may be more than one route from A to B, and most of the time, the roads have speed limits.","categories":[],"infobox_types":[],"annotations":[{"uri":"Theory","surface_form":"theory","offset":41},{"uri":"Mathematics","surface_form":"mathematics","offset":53},{"uri":"Function_(mathematics)","surface_form":"function","offset":174},{"uri":"Interval_(mathematics)","surface_form":"interval","offset":272},{"uri":"Lev_Pontryagin","surface_form":"Lev Pontryagin","offset":475},{"uri":"Richard_E._Bellman","surface_form":"Richard Bellman","offset":516}]}